{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83b622ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import JavascriptException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93ce909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns needed for csv.DictWriter\n",
    "field_names = [\n",
    "    \"link\",\n",
    "    \"listing_title\",\n",
    "    \"listing_mileage\",\n",
    "    \"primary_price\",\n",
    "    \"deal_gauge\",\n",
    "    \"exterior_color\",\n",
    "    \"interior_color\",\n",
    "    \"drivetrain\",\n",
    "    \"mpg\",\n",
    "    \"fuel_type\",\n",
    "    \"transmission\",\n",
    "    \"engine\",\n",
    "    \"vin\",\n",
    "    \"stock_number\",\n",
    "    \"vehicle_history\",\n",
    "    \"seller_name\",\n",
    "    \"price_history\",\n",
    "]\n",
    "\n",
    "# Helper function for extracting elements\n",
    "def extract_element(driver, by, value):\n",
    "    try:\n",
    "        return driver.find_element(by, value).text\n",
    "    except NoSuchElementException:\n",
    "        return np.nan\n",
    "\n",
    "# Initialize blank.csv with header. \n",
    "# Only needed when cars.csv doesn't exist. If so, rename to cars.csv\n",
    "def create_blank():\n",
    "    file_path = \"blank.csv\"\n",
    "    with open(file_path, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(field_names)\n",
    "\n",
    "# create_blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0374c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Selenium WebDriver\n",
    "chrome_service = Service(executable_path='tools1_env/bin/chromedriver')\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\")\n",
    "# chrome_options.add_argument(\"--headless\") # Run without GUI\n",
    "# Running in headless seems to break javascript.\n",
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da1699f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages: 301 - 302\n",
      "301\n",
      "302\n",
      "Done.\n",
      "CPU times: user 1.4 s, sys: 81.8 ms, total: 1.48 s\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Edit these values:\n",
    "PAGES_TO_SCRAPE = 2\n",
    "\n",
    "# If df has 100 rows, we want to start on page 6 since that would be the 101-120 listings.\n",
    "df = pd.read_csv('cars.csv')\n",
    "page_start = len(df)//20 + 1\n",
    "# After running the scraper for a while, the numbers got desynced.\n",
    "page_start = 301\n",
    "\n",
    "# Print total listings to scrape\n",
    "# print(f\"Listings: {(page_start-1)*20 + 1} - {(page_start-1+PAGES_TO_SCRAPE-1)*20 + 20}\")\n",
    "# 1&1 = 1-20  1&2 = 1-40  2&1 = 21-40  ...\n",
    "\n",
    "csvfile = 'cars.csv'\n",
    "with open(csvfile, 'a', newline='') as csvfile: # append mode\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "\n",
    "    # Loop through search result pages\n",
    "    print(f\"Pages: {page_start} - {page_start+PAGES_TO_SCRAPE-1}\")\n",
    "    for page in range(page_start, page_start+PAGES_TO_SCRAPE):\n",
    "        base_url = f\"https://www.cars.com/shopping/results/?fuel_slugs[]=gasoline&page_size=20&page={page}&maximum_distance=10&sort=listed_at&stock_type=used&zip=80210\"\n",
    "        # Need sort=listed_at (\"Oldest listed\") and page_size=20.\n",
    "        # maximum_distance and zip should be consistent for data integrity.\n",
    "        # fuel_slugs[]=gasoline focus on gasoline vehicles.\n",
    "        # stock_type=used focus on used vehicles.\n",
    "        driver.get(base_url)\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        print(f\"{page}\")# : {(page-1)*20 + 1} - {(page-1)*20 + 20}\") # current block of listings\n",
    "        # 1=1-20 2=21-40 ...\n",
    "\n",
    "        # Find the vehicle card elements, then iterate through them\n",
    "        vehicle_cards = driver.find_elements(By.CLASS_NAME, \"vehicle-card-link\")\n",
    "        for vehicle_card in vehicle_cards:\n",
    "            # Follow link to individual listing page\n",
    "            link = vehicle_card.get_attribute(\"href\")\n",
    "            if \"?attribution_type=premier\" in link:\n",
    "                continue  # Skip sponsored listing\n",
    "            vehicle_card.send_keys(Keys.CONTROL + Keys.RETURN) # in new tab\n",
    "            # Switch to the new tab\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            driver.implicitly_wait(2)    \n",
    "\n",
    "            \n",
    "            # javascript \n",
    "            deal_gauge = np.nan\n",
    "            try:\n",
    "                deal_gauge = driver.execute_script('return document.querySelector(\".deal-gauge-list-price-description\").textContent')\n",
    "            except JavascriptException:\n",
    "                pass\n",
    "            \n",
    "            primary_price = np.nan\n",
    "            try:\n",
    "                primary_price = driver.execute_script('return document.querySelector(\".primary-price\").textContent')\n",
    "            except JavascriptException:\n",
    "                pass\n",
    "            \n",
    "            # vehicle_history fancy-description-list\n",
    "            vehicle_history_section = driver.find_element(By.CLASS_NAME, 'sds-page-section.vehicle-history-section')\n",
    "            if 'fancy-description-list' in vehicle_history_section.get_attribute('innerHTML'):\n",
    "                vehicle_history = vehicle_history_section.find_element(By.CLASS_NAME, 'fancy-description-list').get_attribute('innerHTML')\n",
    "                vehicle_history = vehicle_history.replace(\"\\n\", \" \")\n",
    "                # Use regex to clean html\n",
    "                vehicle_history = ' '.join(vehicle_history.split()) # remove whitespace\n",
    "                vehicle_history = re.sub(r'<\\w+[^>]*>', '', vehicle_history) # remove opening HTML tags\n",
    "                history_items = vehicle_history.split('</dd> ')\n",
    "                # Create a dictionary to store the key-value pairs\n",
    "                history_dict = {}\n",
    "                for item in history_items:\n",
    "                    key, value = item.split('</dt> ')\n",
    "                    key = key.replace('<dt>', '')\n",
    "                    history_dict[key] = value\n",
    "                # Remove the last </dd> tag from the last value in the dictionary\n",
    "                last_key = list(history_dict.keys())[-1]\n",
    "                history_dict[last_key] = history_dict[last_key].replace('</dd>', '')\n",
    "                vehicle_history = history_dict\n",
    "\n",
    "            else:\n",
    "                vehicle_history = np.nan\n",
    "            \n",
    "            # Price history table\n",
    "            price_history_data = []\n",
    "            try:\n",
    "                price_history_table = driver.find_element(By.CSS_SELECTOR, 'div.price-history table')\n",
    "                rows = price_history_table.find_elements(By.TAG_NAME, 'tr')\n",
    "                for row in rows:\n",
    "                    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "                    # Assuming each row has three cells (date, price change, list price)\n",
    "                    if len(cells) == 3:\n",
    "                        price_history_date = cells[0].get_attribute('textContent').strip()\n",
    "                        price_history_price_change = cells[1].get_attribute('textContent').strip()\n",
    "                        price_history_list_price = cells[2].get_attribute('textContent').strip()\n",
    "                        \n",
    "                        row_data = (price_history_date, price_history_price_change, price_history_list_price)\n",
    "                        price_history_data.append(row_data)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            # Create a dictionary with the extracted data, then append it to csv.\n",
    "            data_to_append = {\n",
    "                \"link\": link,\n",
    "                \"listing_title\": extract_element(driver, By.CLASS_NAME, \"listing-title\"),\n",
    "                \"listing_mileage\": extract_element(driver, By.CLASS_NAME, \"listing-mileage\"),\n",
    "                \"primary_price\": primary_price,\n",
    "                \"deal_gauge\": deal_gauge,\n",
    "                \"exterior_color\": extract_element(driver, By.XPATH, '//dt[text()=\"Exterior color\"]/following-sibling::dd'),\n",
    "                \"interior_color\": extract_element(driver, By.XPATH, '//dt[text()=\"Interior color\"]/following-sibling::dd'),\n",
    "                \"drivetrain\": extract_element(driver, By.XPATH, '//dt[text()=\"Drivetrain\"]/following-sibling::dd'),\n",
    "                \"mpg\": extract_element(driver, By.XPATH, '//dt[text()=\"MPG\"]/following-sibling::dd'),\n",
    "                \"fuel_type\": extract_element(driver, By.XPATH, '//dt[text()=\"Fuel type\"]/following-sibling::dd'),\n",
    "                \"transmission\": extract_element(driver, By.XPATH, '//dt[text()=\"Transmission\"]/following-sibling::dd'),\n",
    "                \"engine\": extract_element(driver, By.XPATH, '//dt[text()=\"Engine\"]/following-sibling::dd'),\n",
    "                \"vin\": extract_element(driver, By.XPATH, '//dt[text()=\"VIN\"]/following-sibling::dd'),\n",
    "                \"stock_number\": extract_element(driver, By.XPATH, '//dt[text()=\"Stock #\"]/following-sibling::dd'),\n",
    "                \"vehicle_history\": vehicle_history,\n",
    "                \"seller_name\": extract_element(driver, By.CLASS_NAME, 'seller-name'),\n",
    "                \"price_history\": price_history_data,\n",
    "            }\n",
    "\n",
    "            writer.writerow(data_to_append)\n",
    "            #print(f\"{data_to_append} \\n\") # DEBUG PRINT \n",
    "\n",
    "            # Close new tab\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d83ae15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicates removed.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates in cars.csv\n",
    "df = pd.read_csv('cars.csv')\n",
    "print(f\"{df.duplicated().sum()} duplicates removed.\")\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv('cars.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af6da92",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Separate listing_title out into make model year etc\n",
    "- For listing that dont have price history, obtain date range of possible \"Listed\" date based on dates above and below them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce179b9",
   "metadata": {},
   "source": [
    "Deal Gauge value based on Avg. market price range:\n",
    "- Over = \"This is a fair deal. Why?\"\n",
    "- Within = \"This is a good deal.\"\n",
    "- Under = \"Great Deal $[...] under\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cf333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code for handling non-gasoline vehicles\n",
    "\n",
    "# # mpg is listed differently for EVs, and also not always listed\n",
    "#         try:\n",
    "#             mpg = driver.find_element(By.XPATH, '//dt[text()=\"MPG\"]/following-sibling::dd').text,\n",
    "#         except NoSuchElementException:\n",
    "#             key_specs_container = driver.find_element(By.ID, 'key-specs-container')\n",
    "#             mpg_section = key_specs_container.find_element(By.XPATH, './/div[@data-qa=\"mpge\"]')\n",
    "#             city_mpg_element = mpg_section.find_element(By.XPATH, './/strong[contains(@class, \"key-spec-value\")][1]').text\n",
    "#             hwy_mpg_element = mpg_section.find_element(By.XPATH, './/strong[contains(@class, \"key-spec-value\")][2]').text\n",
    "#             mpg = f\"MPGe {city_mpg_element} city ; {hwy_mpg_element} hwy.\"\n",
    "#         except Exception:\n",
    "#             mpg = np.nan\n",
    "        \n",
    "#         # fuel_type not always listed\n",
    "#         try:\n",
    "#             fuel_type = driver.find_element(By.XPATH, '//dt[text()=\"Fuel type\"]/following-sibling::dd').text\n",
    "#         except NoSuchElementException:\n",
    "#             fuel_type = np.nan\n",
    "#             # will want to verify that fuel type is electric from mpg html dump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
